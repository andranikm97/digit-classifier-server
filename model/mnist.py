# -*- coding: utf-8 -*-
"""MNIST NN (PyTorch).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SN5ij_rJSP2Zu8NBMtEGxDRbp1dKuztt
"""

import os

import torch
from torch import nn, optim

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class NeuralNetwork(nn.Module):
  def __init__(self):
    super().__init__()
    self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=2)
    self.conv2 = nn.Conv2d(16, 32, 5, 1, 2)
    self.maxPool = nn.MaxPool2d(2)
    self.linear = nn.Linear(32 * 7 * 7, 10)
  
  def forward(self, x):
    h1 = self.maxPool(nn.functional.relu(self.conv1(x)))
    h2 = self.maxPool(nn.functional.relu(self.conv2(h1)))
    h3 = h2.view(h2.size(0), -1)
    out = self.linear(h3)
    return out

checkpoint_path = None
if os.path.exists('model/extended.pt'):
  checkpoint_path = "model/extended.pt"
else:
  checkpoint_path = "model/original.pt"

checkpoint = torch.load(checkpoint_path, map_location=torch.device(device))

model = NeuralNetwork()
model_state_dict = checkpoint["model_state_dict"]
model.load_state_dict(model_state_dict)

optimiser = optim.Adam(model.parameters(), lr=0.01)
optimizer_state_dict = checkpoint["optimizer_state_dict"]
optimiser.load_state_dict(optimizer_state_dict)

loss_fn = nn.CrossEntropyLoss()

def train_model(X, Y):
  model.train()
  logits = model(X)
  J = loss_fn(logits, Y)
  model.zero_grad()
  J.backward()
  optimiser.step()

  saveModel()
  return model, optimiser

def predict(example):
  example = torch.tensor(example)
  example = example / 255.0
  if example.dtype == torch.float64:
      example = example.to(torch.float32)
  model.eval()
  with torch.no_grad():
      output = model(example)
  model.train()
  output = torch.argmax(torch.nn.Softmax(dim=1)(output)).item()
  return output

def saveModel():
  nOfNewExamples = 0
  
  if os.path.exists('model/extended.pt'):
    current = torch.load('model/extended.pt', map_location=torch.device(device))
    nOfNewExamples = current['numberOfNewExamples']
  
  state = {
  'model_state_dict': model.state_dict(),
  'optimizer_state_dict': optimiser.state_dict(),
  'numberOfNewExamples': nOfNewExamples + 1
  }

  torch.save(state, 'model/extended.pt')
  return
